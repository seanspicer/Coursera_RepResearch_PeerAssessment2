---
title: "StormAnalysis"
author: "Sean Spicer"
date: "November 18, 2015"
output:
  html_document:
    keep_md: yes
    toc: yes
---

## Reproducible Research: Peer Assessment 2

### 1. Assignment

The basic goal of this assignment is to explore the NOAA Storm Database and answer some basic questions about severe weather events. You must use the database to answer the questions below and show the code for your entire analysis. Your analysis can consist of tables, figures, or other summaries. You may use any R package you want to support your analysis.

### 2. Synopsis

[WRITE]


### 3. Data Processing

Set working Directory
```{r, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# Clear all;
rm(list=ls());
setwd("C:/Users/s.spicer/Documents/GitHub/Coursera_RepResearch_PeerAssessment2")
```

##### 3.1. Load libraries
Load libs for getting and processing data
```{r, warning=FALSE, message=FALSE}
library(RCurl) 
library(R.utils) 
library(reshape2) 
library(dplyr) 
library(reshape2) 
library(ggplot2)
library(scales)
library(gridExtra)
library(grid)
```

##### 3.2. Download source file, extract, and cache it in an RData file
RData file is reused if it exists.  Delete it to re-run this chunk
```{r, warning=FALSE, message=FALSE}
doProcessing = TRUE

# check if processed storm data exists
if(file.exists("./data/ProcessedStormData.RData")){
  processedStormData = readRDS("./data/ProcessedStormData.RData")
  doProcessing = FALSE
}

if(doProcessing){
  
  # create a data dir if it doesn't exist
  if(!file.exists("./data")){
      dir.create("./data")
  }
  # load file from URL to bz2 file in data dir
  if(!file.exists("./data/StormData.csv.bz2")){
    fileUrl = "https://d396qusza40orc.cloudfront.net/repdata/data/StormData.csv.bz2"
    destPath = "./data/StormData.csv.bz2"
    binData = getBinaryURL(fileUrl, 
                            ssl.verifypeer=0L, 
                            followlocation=1L)
    destFileHandle = file(destPath, open="wb")
    writeBin(binData,destFileHandle)
    close(destFileHandle)
  }
  # unzip bz2 file to csv
  if(!file.exists("./data/StormData.csv")){
    filePath = "./data/StormData.csv.bz2"
    destPath = "./data/StormData.csv"
    bunzip2(filePath,destPath,overwrite=TRUE, remove=FALSE)
  }
}
```


##### 3.3. Read uncompressed data and process it
Read the .csv file and keep only required columns
```{r, cache = TRUE}
if(doProcessing){
  rawStormData = read.csv("./data/StormData.csv")

  rawStormData = rawStormData[, c("BGN_DATE", "EVTYPE", "FATALITIES", "INJURIES", "PROPDMG", "PROPDMGEXP", "CROPDMG", "CROPDMGEXP")]

  # Get number of observations
  nObs = nrow(rawStormData)

  # figure out how many observations there are per year
  rawStormData$year = as.numeric(format(as.Date(rawStormData$BGN_DATE, format = "%m/%d/%Y"), "%Y"))
  yearCount = rawStormData %>% group_by(year) %>% summarise("Count" = n());
  
}
```

##### 3.4. Reduce EVTYPE into 11 levels
Determine number of unique EVTYPES:
```{r, cache=TRUE}

nTypes = length(unique(rawStormData$EVTYPE))

```

The EVTYPE contains 985 unique source events. Similar types are combined into 9 EventTypeGroups.  This covers
of 901900 / 902297 (99%) of all records
```{r, cache = TRUE}
if(doProcessing){
  rawStormData$EventTypeGroup = NA
  
  rawStormData[grepl("tstm|thunderstorm|lightning", 
                         rawStormData$EVTYPE, ignore.case = TRUE), "EventTypeGroup"] = "Thunderstorms/Lightning"
  rawStormData[grepl("tornado|spout|funnel|whirlwind", 
                         rawStormData$EVTYPE, ignore.case = TRUE), "EventTypeGroup"] = "Tornados"
  rawStormData[grepl("fire|smoke|volcanic", 
                         rawStormData$EVTYPE, ignore.case = TRUE), "EventTypeGroup"] = "Fire/Volcanic activity"
  rawStormData[grepl("precipitation|rain|hail|drizzle|wet|percip|fog", 
                         rawStormData$EVTYPE, ignore.case = TRUE), "EventTypeGroup"] = "Wet Precipitation"
  rawStormData[grepl("wind|storm|wnd|depression|hurricane|typhoon|burst|wall cloud", 
                         rawStormData$EVTYPE, ignore.case = TRUE), "EventTypeGroup"] = "Storm"
  rawStormData[grepl("slide|erosion|slump", 
                         rawStormData$EVTYPE, ignore.case = TRUE), "EventTypeGroup"] = "Erosion"
  rawStormData[grepl("warmth|warm|heat|dry|hot|drought|thermia|temperature record|record temperature|record high", 
                         rawStormData$EVTYPE, ignore.case = TRUE), "EventTypeGroup"] = "High Temperatures"
  rawStormData[grepl("cold|cool|ice|icy|frost|freeze|snow|winter|wintry|wintery|blizzard|chill|freezing|avalanche|glaze|sleet", 
                         rawStormData$EVTYPE, ignore.case = TRUE), "EventTypeGroup"] = "Winter Weather"
  rawStormData[grepl("flood|surf|blow-out|swells|fld|dam break|seas|high water|tide|tsunami|wave|current|marine|drowning", 
                         rawStormData$EVTYPE, ignore.case = TRUE), "EventTypeGroup"] = "Flooding"

  
  # Kill anything else
  rawStormData = rawStormData[complete.cases(rawStormData[, "EventTypeGroup"]), ]
  rawStormData$EventTypeGroup = as.factor(rawStormData$EventTypeGroup)
}
```

##### 3.5. Normalize PROPDMG, CROPDMG, PROPDMGEXP & CROPDMGEXP values
Damage values are given with respect to an expential value.  Multiply through to get comparable values.
```{r, cache = TRUE}
if(doProcessing){
  
  # convert symbol to a power of 10
  toTenPower = function(x){
    if(is.numeric(x)) {
      x = x
    }
    else if(grepl("h", x, ignore.case=TRUE)) {
      x = 2
    }
    else if(grepl("k", x, ignore.case=TRUE)) {
      x = 3
    }
    else if(grepl("m", x, ignore.case=TRUE)) {
      x = 6
    }
    else if(grepl("b", x, ignore.case=TRUE)) {
      x = 9
    }
    else if(x == "" || x == " "){
      x = 0
    }
    else{
      x = NA
    }
    x
  }
   
  # mutiply through by exponent
  calculateAmount = function(num, exp){
    pow = toTenPower(exp)
    if(is.numeric(num)){
      num = num * (10 ^ pow)
    }
    
    if(!is.numeric(num)){
      num = 0
    }
    
    num
  }
  
  # Merge into a TotalDamage value (Prop + Crop)
  rawStormData$PropDamage = mapply(calculateAmount, rawStormData$PROPDMG, rawStormData$PROPDMGEXP)
  rawStormData$CropDamage = mapply(calculateAmount, rawStormData$CROPDMG, rawStormData$CROPDMGEXP)
  rawStormData$TotalDamage = rawStormData$PropDamage + rawStormData$CropDamage
  
  # Remove rows where total damage is NA (cannot be computed)
  rawStormData = rawStormData[!is.na(rawStormData$TotalDamage),];
  
}
```

##### 3.6. Create aggregated datasets and variables for plots
The final data frames must be recast to be used in certain plot funtions
```{r, cache = TRUE}
if(doProcessing){
  
  # Group By EventTypeGroup
  processedStormData = rawStormData %>% group_by(EventTypeGroup) %>% summarise("NumEvents" = n(),
                                                                               "PropDamage" = sum(PropDamage),
                                                                               "CropDamage" = sum(CropDamage), 
                                                                               "TotalDamage" = sum(TotalDamage),
                                                                               "Fatalities" = sum(FATALITIES),
                                                                               "Injuries" = sum(INJURIES));
  
  processedStormData$PropDamage.PerEvent = processedStormData$PropDamage / processedStormData$NumEvents;
  processedStormData$CropDamage.PerEvent = processedStormData$CropDamage / processedStormData$NumEvents;
  processedStormData$TotalDamage.PerEvent = processedStormData$TotalDamage / processedStormData$NumEvents;
  processedStormData$Fatalities.PerEvent = processedStormData$Fatalities / processedStormData$NumEvents;
  processedStormData$Injuries.PerEvent = processedStormData$Injuries / processedStormData$NumEvents;
  
}
```

##### 3.8. Save processedStormData to file 
```{r}
if(doProcessing){
  saveRDS(processedStormData, file="./data/ProcessedStormData.RData")
}
```  


### 4. Results
##### 4.1. Show a results table
Display the results of the processing
```{r, fig.width=10, warning=FALSE}
tableData = processedStormData[, c(1,2,8,9,10,11,12)];

tt = ttheme_default(
                    core = list(fg_params=list(cex = 0.75)),
    colhead = list(fg_params=list(cex = 0.75)),
    rowhead = list(fg_params=list(cex = 0.75)))
tbl = tableGrob(tableData, rows=NULL, theme=tt);
grid.draw(tbl);
```

##### 4.2. Population Impact of Storms - Injuries vs. Fatalities

```{r, fig.width=10, fig.height=8, warning=FALSE}
populationHealth = processedStormData[, c(1, 11, 12)];
populationHealth = melt(populationHealth)
ggplot(data=populationHealth) + 
  geom_bar(aes(x=EventTypeGroup, y=value, fill=variable), stat="identity", position="dodge") +
  scale_fill_brewer(palette = "Set1", guide = guide_legend(title = "")) + 
  scale_y_continuous(breaks = pretty_breaks(6)) +
  labs(x = "Event Type", y = "Rate / Event", title = "Impact of Storms on Population") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1), 
        panel.grid.major = element_line(colour = "grey90"),
        panel.grid.minor = element_blank(), 
        panel.background = element_blank(),
        axis.ticks = element_blank())

```

##### 4.3. Economic Impact of Storm Damage

```{r, fig.width=10, fig.height=8, warning=FALSE}
propertyDamage = processedStormData[, c(1,8,9,10)];
propertyDamage = melt(propertyDamage)
ggplot(data=propertyDamage) + 
  geom_bar(aes(x=EventTypeGroup, y=value, fill=variable), stat="identity", position="dodge") +
  scale_fill_brewer(palette = "Set1", guide = guide_legend(title = "")) + 
  labs(x = "Event Type", y = "Dollars / Event", title = "Impact of Storms on Property") +
  scale_y_continuous(breaks = pretty_breaks(6), labels = comma) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1), 
        panel.grid.major = element_line(colour = "grey90"),
        panel.grid.minor = element_blank(), 
        panel.background = element_blank(),
        axis.ticks = element_blank())
```